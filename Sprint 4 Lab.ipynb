{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef6271e6-0e98-48d5-ad3e-6c26c2edff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json for parsing our JSONL files from the data set\n",
    "import json\n",
    "\n",
    "# numpy and pandas for efficient manipulation of data structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "# spacy for embedding tokens from the dataset into vectors\n",
    "import spacy\n",
    "# or word2vec, we're trying things\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# scikit-learn for the various models to try\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f365871-c35b-41e0-847c-5f7d6900ff39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bibcode</th>\n",
       "      <th>label_studio_id</th>\n",
       "      <th>ner_ids</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>section</th>\n",
       "      <th>tokens</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019MNRAS.486.5558S</td>\n",
       "      <td>487</td>\n",
       "      <td>[62, 62, 62, 62, 62, 62, 62, 15, 62, 62, 62, 6...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-Instrument, O, O, O, O...</td>\n",
       "      <td>fulltext</td>\n",
       "      <td>[Whilst, a, reasonable, harmonic, fit, to, the...</td>\n",
       "      <td>fulltext_487_2019MNRAS.486.5558S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018MNRAS.478.5533F</td>\n",
       "      <td>1129</td>\n",
       "      <td>[62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>fulltext</td>\n",
       "      <td>[comparison, once, the, angular, positions, of...</td>\n",
       "      <td>fulltext_1129_2018MNRAS.478.5533F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018MNRAS.480.3062L</td>\n",
       "      <td>1086</td>\n",
       "      <td>[62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>acknowledgments</td>\n",
       "      <td>[ACKNOWLEDGEMENTS, The, authors, thank, an, an...</td>\n",
       "      <td>acknowledgments_1086_2018MNRAS.480.3062L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016MNRAS.457.1786M</td>\n",
       "      <td>1135</td>\n",
       "      <td>[22, 62, 62, 62, 62, 21, 13, 44, 44, 21, 62, 1...</td>\n",
       "      <td>[B-Person, O, O, O, O, B-Organization, B-Grant...</td>\n",
       "      <td>acknowledgments</td>\n",
       "      <td>[BDM, gratefully, acknowledges, support, from,...</td>\n",
       "      <td>acknowledgments_1135_2016MNRAS.457.1786M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019MNRAS.482L...9B</td>\n",
       "      <td>559</td>\n",
       "      <td>[62, 62, 62, 22, 53, 22, 53, 22, 53, 22, 53, 2...</td>\n",
       "      <td>[O, O, O, B-Person, I-Person, B-Person, I-Pers...</td>\n",
       "      <td>acknowledgments</td>\n",
       "      <td>[ACKNOWLEDGEMENTS, We, thank, Dougal, Mackey,,...</td>\n",
       "      <td>acknowledgments_559_2019MNRAS.482L...9B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bibcode  label_studio_id  \\\n",
       "0  2019MNRAS.486.5558S              487   \n",
       "1  2018MNRAS.478.5533F             1129   \n",
       "2  2018MNRAS.480.3062L             1086   \n",
       "3  2016MNRAS.457.1786M             1135   \n",
       "4  2019MNRAS.482L...9B              559   \n",
       "\n",
       "                                             ner_ids  \\\n",
       "0  [62, 62, 62, 62, 62, 62, 62, 15, 62, 62, 62, 6...   \n",
       "1  [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...   \n",
       "2  [62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 6...   \n",
       "3  [22, 62, 62, 62, 62, 21, 13, 44, 44, 21, 62, 1...   \n",
       "4  [62, 62, 62, 22, 53, 22, 53, 22, 53, 22, 53, 2...   \n",
       "\n",
       "                                            ner_tags          section  \\\n",
       "0  [O, O, O, O, O, O, O, B-Instrument, O, O, O, O...         fulltext   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...         fulltext   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  acknowledgments   \n",
       "3  [B-Person, O, O, O, O, B-Organization, B-Grant...  acknowledgments   \n",
       "4  [O, O, O, B-Person, I-Person, B-Person, I-Pers...  acknowledgments   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Whilst, a, reasonable, harmonic, fit, to, the...   \n",
       "1  [comparison, once, the, angular, positions, of...   \n",
       "2  [ACKNOWLEDGEMENTS, The, authors, thank, an, an...   \n",
       "3  [BDM, gratefully, acknowledges, support, from,...   \n",
       "4  [ACKNOWLEDGEMENTS, We, thank, Dougal, Mackey,,...   \n",
       "\n",
       "                                  unique_id  \n",
       "0          fulltext_487_2019MNRAS.486.5558S  \n",
       "1         fulltext_1129_2018MNRAS.478.5533F  \n",
       "2  acknowledgments_1086_2018MNRAS.480.3062L  \n",
       "3  acknowledgments_1135_2016MNRAS.457.1786M  \n",
       "4   acknowledgments_559_2019MNRAS.482L...9B  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the JSONL file\n",
    "raw = []\n",
    "with open(\"train.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        raw.append(json.loads(line))\n",
    "\n",
    "# throw it into a dataframe\n",
    "df = pd.DataFrame(raw)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f209813-003a-466e-8c1f-71fbec421dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it'll be far more effective to store NER IDs vs names\n",
    "# but names are nice, so map them all out\n",
    "tag_map = {}\n",
    "for id_list, name_list in zip(df[\"ner_ids\"], df[\"ner_tags\"]):\n",
    "    for tag_id, tag_name in zip(id_list, name_list):\n",
    "        tag_map[tag_id] = tag_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "906319f1-9749-4c11-899f-7ad40b8f05b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for null values\n",
      " bibcode            0\n",
      "label_studio_id    0\n",
      "ner_ids            0\n",
      "ner_tags           0\n",
      "section            0\n",
      "tokens             0\n",
      "unique_id          0\n",
      "dtype: int64 \n",
      "\n",
      "checking for NaN values\n",
      " bibcode            0\n",
      "label_studio_id    0\n",
      "ner_ids            0\n",
      "ner_tags           0\n",
      "section            0\n",
      "tokens             0\n",
      "unique_id          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# are there any null or NaN values we need to be worried about?\n",
    "print(\"checking for null values\\n\", df.isnull().sum(), \"\\n\")\n",
    "print(\"checking for NaN values\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c967d4e5-72be-40de-afb6-a49655b4c866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28606"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are there tokens with special characters?\n",
    "all_tokens = np.concatenate(df[\"tokens\"])\n",
    "special = []\n",
    "for token in all_tokens:\n",
    "    if not token.isalpha():\n",
    "        special.append(token)\n",
    "len(np.unique(special))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1947d22e-0016-4327-99c4-f08e9e7a0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes, lots. maybe we will deal with that later,\n",
    "# that could affect accuracy, but who knows yet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5cb8b7f-84e9-4f5e-af2c-992b3833471a",
   "metadata": {},
   "source": [
    "# either this cell or the next should be enabled. toggle cells with 'r' and 'y'\n",
    "\n",
    "# now we need to transform the tokens into embeddings\n",
    "# use spacy using the medium size dictionary to do that\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# function to vectorize a list of tokens\n",
    "def vectorize(tokens):\n",
    "    return [nlp(token).vector for token in tokens]\n",
    "\n",
    "# and chew through all the tokens and transform them\n",
    "# TODO: this might be better if we also kept the 'section' feature\n",
    "# for example, names might be more common in acknowledgements\n",
    "# for now, just vectorize words\n",
    "# for now loop with print statements cause this is taking a while\n",
    "\n",
    "def transform(data, filename, verbose=False, batch_size=100):\n",
    "    transformed_data = []\n",
    "    for i in range(len(data)):\n",
    "        if verbose and i % batch_size == 0:\n",
    "            print(f\"starting record {i}\")\n",
    "        transformed_data += vectorize(data.loc[i][\"tokens\"])\n",
    "    \n",
    "    # let's save that off so we don't necessarily have to do this again...\n",
    "    # each entry has a different length since it's not always the same number of tokens\n",
    "    # cast this to a numpy object array\n",
    "    \n",
    "    X = np.array(transformed_data)\n",
    "    np.save(filename, X)\n",
    "    return X\n",
    "\n",
    "# comment out below if file is already created  \n",
    "# X = transform(df, \"vectorized_X_training\", verbose=True, batch_size=100)\n",
    "# instead of the above, we can just load from the file\n",
    "X_test = np.load(\"vectorized_X_training.npy\", allow_pickle=True)\n",
    "\n",
    "# pull out the labels\n",
    "y_test = np.concatenate(df[\"ner_ids\"].to_numpy())\n",
    "\n",
    "# do the same for the validation data\n",
    "raw = []\n",
    "with open(\"validate.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        raw.append(json.loads(line))\n",
    "\n",
    "# throw it into a dataframe\n",
    "df_validate = pd.DataFrame(raw)\n",
    "# comment out below if file is already created  \n",
    "# X_test = transform(df_validate, \"vectorized_X_testing.npy\", verbose=True, batch_size=100)\n",
    "# instead of the above, we can just load from the file\n",
    "X_test = np.load(\"vectorized_X_testing.npy\", allow_pickle=True)\n",
    "y_test = np.concatenate(df_validate[\"ner_ids\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2032fc34-1e95-4240-b170-06cc3a9403dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# either this cell or the next should be enabled. toggle cells with 'r' and 'y'\n",
    "\n",
    "# alternatively, use Word2Vec for this\n",
    "# TODO: understand parameters better\n",
    "\n",
    "# the min count not being zero is a problem, sometimes words can't be encoded\n",
    "min_count = 0\n",
    "# the vector size makes a huge difference on how successful various algorithsm below are\n",
    "vector_size = 20\n",
    "\n",
    "model = Word2Vec(sentences=df[\"tokens\"], vector_size=vector_size, window=5, min_count=min_count, sg=1)\n",
    "# vectorize each word\n",
    "X_train = np.zeros([len(all_tokens), vector_size])\n",
    "for i, token in enumerate(all_tokens):\n",
    "    X_train[i] = model.wv[token]\n",
    "\n",
    "y_train = np.concatenate(df[\"ner_ids\"].to_numpy())\n",
    "\n",
    "# so the same with the validation data\n",
    "raw = []\n",
    "with open(\"validate.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        raw.append(json.loads(line))\n",
    "\n",
    "# throw it into a dataframe\n",
    "df_validate = pd.DataFrame(raw)\n",
    "\n",
    "model_validate = Word2Vec(sentences=df_validate[\"tokens\"], vector_size=vector_size, window=5, min_count=min_count, sg=1)\n",
    "# vectorize each word\n",
    "all_test_tokens = np.concatenate(df_validate[\"tokens\"])\n",
    "X_test = np.zeros([len(all_test_tokens), vector_size])\n",
    "for i, token in enumerate(all_test_tokens):\n",
    "    X_test[i] = model_validate.wv[token]\n",
    "\n",
    "y_test = np.concatenate(df_validate[\"ner_ids\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "887a4ccb-3985-4e66-bd89-5d3fecba34f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573132, 10) (573132,)\n",
      "(447366, 10) (573132,)\n"
     ]
    }
   ],
   "source": [
    "# sanity test on data\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e56ae2a-694b-45f5-af9c-e29f1bd671db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the categorizations\n",
    "labels = np.unique(y_train).tolist()\n",
    "# also get their names for prettier reports\n",
    "tag_map = dict(zip(np.concatenate(df[\"ner_ids\"]), np.concatenate(df[\"ner_tags\"])))\n",
    "# remove tag for 'O', we don't want that in reports\n",
    "# it's so common it heavily biases the f-scores\n",
    "del(tag_map[62])\n",
    "# now create lists for the IDs and tags in the same order\n",
    "# sklearn.metrics.classification_report requires two different parameters\n",
    "tag_ids = sorted(tag_map.keys())\n",
    "tag_names = [tag_map[i] for i in tag_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "865a5fe1-d948-47e2-b6be-ad64eb1d6a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573132, 100) (573132,)\n",
      "(447366, 100) (447366,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into training vs testing\n",
    "# TODO: when properly working on the DEAL data, it is already split\n",
    "# move this to a multi-file pipeline\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)\n",
    "\n",
    "# basic stats for sanity check on matrix sizes\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccd668ec-9a15-4ee3-8cab-c22439f547e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick helper function for printing classification reports\n",
    "def report(y_pred):\n",
    "    print(classification_report(\n",
    "        y_pred=y_pred,\n",
    "        y_true=y_test,\n",
    "        labels=tag_ids,\n",
    "        target_names=tag_names,\n",
    "        zero_division=np.nan\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8033f615-e570-4ca3-bdab-1947e71ee90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple stochastic gradient descent\n",
    "sgd = SGDClassifier()\n",
    "# fit and predict\n",
    "sgd.partial_fit(X_train, y_train, labels)\n",
    "y_pred = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d01d49a-0ece-4179-871e-377c3d781b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                B-Archive        nan      0.00      0.00       153\n",
      "        B-CelestialObject        nan      0.00      0.00      2285\n",
      "  B-CelestialObjectRegion        nan      0.00      0.00       150\n",
      "        B-CelestialRegion        nan      0.00      0.00       102\n",
      "               B-Citation       0.00      0.00      0.00      4820\n",
      "          B-Collaboration        nan      0.00      0.00       238\n",
      "      B-ComputingFacility        nan      0.00      0.00       360\n",
      "               B-Database        nan      0.00      0.00       199\n",
      "                B-Dataset        nan      0.00      0.00       222\n",
      " B-EntityOfFutureInterest        nan      0.00      0.00        52\n",
      "                  B-Event        nan      0.00      0.00        37\n",
      "             B-Fellowship        nan      0.00      0.00       326\n",
      "                B-Formula        nan      0.00      0.00      1541\n",
      "                  B-Grant        nan      0.00      0.00      2834\n",
      "             B-Identifier        nan      0.00      0.00        94\n",
      "             B-Instrument        nan      0.00      0.00       683\n",
      "               B-Location        nan      0.00      0.00      1157\n",
      "                B-Mission        nan      0.00      0.00       105\n",
      "                  B-Model        nan      0.00      0.00      1412\n",
      "B-ObservationalTechniques        nan      0.00      0.00       102\n",
      "            B-Observatory        nan      0.00      0.00       735\n",
      "           B-Organization       0.30      0.08      0.13      6054\n",
      "                 B-Person       0.00      0.00      0.00      3267\n",
      "               B-Proposal        nan      0.00      0.00        76\n",
      "               B-Software       0.00      0.00      0.00       839\n",
      "                 B-Survey        nan      0.00      0.00       620\n",
      "                    B-Tag        nan      0.00      0.00        53\n",
      "              B-Telescope        nan      0.00      0.00      1257\n",
      "            B-TextGarbage        nan      0.00      0.00        47\n",
      "                    B-URL        nan      0.00      0.00       227\n",
      "             B-Wavelength        nan      0.00      0.00      2869\n",
      "                I-Archive        nan      0.00      0.00       348\n",
      "        I-CelestialObject        nan      0.00      0.00      1347\n",
      "  I-CelestialObjectRegion        nan      0.00      0.00       139\n",
      "        I-CelestialRegion        nan      0.00      0.00       275\n",
      "               I-Citation       0.17      0.55      0.27     14072\n",
      "          I-Collaboration       0.00      0.00      0.00       437\n",
      "      I-ComputingFacility        nan      0.00      0.00       690\n",
      "               I-Database        nan      0.00      0.00       225\n",
      "                I-Dataset        nan      0.00      0.00       232\n",
      " I-EntityOfFutureInterest        nan      0.00      0.00        13\n",
      "                  I-Event        nan      0.00      0.00       170\n",
      "             I-Fellowship       0.00      0.00      0.00       839\n",
      "                I-Formula       0.00      0.00      0.00      6482\n",
      "                  I-Grant       0.03      0.00      0.00      3594\n",
      "             I-Identifier        nan      0.00      0.00        26\n",
      "             I-Instrument        nan      0.00      0.00       176\n",
      "               I-Location        nan      0.00      0.00       397\n",
      "                I-Mission        nan      0.00      0.00        43\n",
      "                  I-Model        nan      0.00      0.00      1025\n",
      "I-ObservationalTechniques        nan      0.00      0.00        88\n",
      "            I-Observatory       0.96      0.09      0.17      1001\n",
      "           I-Organization       0.00      0.00      0.00     12021\n",
      "                 I-Person        nan      0.00      0.00      1948\n",
      "               I-Proposal        nan      0.00      0.00        87\n",
      "               I-Software        nan      0.00      0.00       269\n",
      "                 I-Survey        nan      0.00      0.00       380\n",
      "                    I-Tag        nan      0.00      0.00        51\n",
      "              I-Telescope        nan      0.00      0.00       596\n",
      "            I-TextGarbage        nan      0.00      0.00        55\n",
      "                    I-URL        nan      0.00      0.00         1\n",
      "             I-Wavelength        nan      0.00      0.00      1895\n",
      "\n",
      "                micro avg       0.14      0.10      0.12     81838\n",
      "                macro avg       0.13      0.01      0.01     81838\n",
      "             weighted avg       0.10      0.10      0.06     81838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5cefd056-c3fe-488a-ba35-2f3c29d16b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 17.27, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.024629\n",
      "Total training time: 0.09 seconds.\n",
      "Norm: 8.65, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.032421\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 10.12, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.001953\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 20.68, NNZs: 20, Bias: -2.000000, T: 573132, Avg. loss: 0.003837\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 13.59, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.007136\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 20.37, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.004445\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 9.76, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.003436\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 16.14, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.006481\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 13.88, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.006675\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 9.04, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.003436\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.91, NNZs: 20, Bias: 4.000000, T: 573132, Avg. loss: 0.037145\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 7.01, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000621\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.15, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.005227\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 9.08, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.000554\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5.31, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000590\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 16.93, NNZs: 20, Bias: 4.000000, T: 573132, Avg. loss: 0.027457\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.99, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.024421\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 14.07, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.020024\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.98, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.017727\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.12, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.019000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.67, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.001387\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 26.48, NNZs: 20, Bias: 4.000000, T: 573132, Avg. loss: 0.147158\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 10.08, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.001377\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 8.26, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000571\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 8.80, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.007339\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 4.90, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000225\n",
      "Total training time: 0.09 seconds.\n",
      "Norm: 11.76, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.019560\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 14.25, NNZs: 20, Bias: 2.000000, T: 573132, Avg. loss: 0.010134\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 9.65, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.001068\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.46, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.011793\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.06, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.002710\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 9.12, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.046954\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6.85, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.003224\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.54, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.016655\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 37.58, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.130245\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.44, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.005273\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 8.42, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.015301\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.17, NNZs: 20, Bias: -6.000000, T: 573132, Avg. loss: 0.017550\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 8.05, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.003687\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 12.01, NNZs: 20, Bias: 2.000000, T: 573132, Avg. loss: 0.006475\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 7.08, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.002315\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.53, NNZs: 20, Bias: -2.000000, T: 573132, Avg. loss: 0.119806\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.23, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.023803\n",
      "Total training time: 0.09 seconds.\n",
      "Norm: 8.12, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000220\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 7.85, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000278\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 12.23, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.068084\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 6.80, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.001413\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 16.82, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.007684\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.93, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000462\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 10.70, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.019323\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 26.62, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.262665\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 10.18, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.010216\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.20, NNZs: 20, Bias: 1.000000, T: 573132, Avg. loss: 0.019945\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6.59, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.001256\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 7.80, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.001050\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 9.52, NNZs: 20, Bias: 2.000000, T: 573132, Avg. loss: 0.007352\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 16.74, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.007654\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 7.46, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000221\n",
      "Total training time: 0.09 seconds.\n",
      "Norm: 11.23, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.001052\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 10.86, NNZs: 20, Bias: 3.000000, T: 573132, Avg. loss: 0.010914\n",
      "Total training time: 0.08 seconds.\n",
      "Norm: 16.52, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.024380\n",
      "Total training time: 0.07 seconds.\n",
      "Norm: 7.04, NNZs: 20, Bias: 0.000000, T: 573132, Avg. loss: 0.000260\n",
      "Total training time: 0.09 seconds.\n",
      "Norm: 18.38, NNZs: 20, Bias: -1.000000, T: 573132, Avg. loss: 0.749632\n",
      "Total training time: 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "# build a simple perceptron\n",
    "per = Perceptron(verbose=1, n_jobs=-1, max_iter=25)\n",
    "# train it and predict\n",
    "per.partial_fit(X_train, y_train, labels)\n",
    "y_pred = per.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b034953-4965-4ac6-bf9c-253083701dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                B-Archive        nan      0.00      0.00       153\n",
      "        B-CelestialObject       0.02      0.12      0.03      2285\n",
      "  B-CelestialObjectRegion        nan      0.00      0.00       150\n",
      "        B-CelestialRegion        nan      0.00      0.00       102\n",
      "               B-Citation       0.01      0.02      0.01      4820\n",
      "          B-Collaboration       0.00      0.00      0.00       238\n",
      "      B-ComputingFacility       0.01      0.19      0.01       360\n",
      "               B-Database       0.00      0.00      0.00       199\n",
      "                B-Dataset        nan      0.00      0.00       222\n",
      " B-EntityOfFutureInterest        nan      0.00      0.00        52\n",
      "                  B-Event       0.00      0.00      0.00        37\n",
      "             B-Fellowship       0.00      0.00      0.00       326\n",
      "                B-Formula       0.00      0.00      0.00      1541\n",
      "                  B-Grant       0.06      0.09      0.07      2834\n",
      "             B-Identifier        nan      0.00      0.00        94\n",
      "             B-Instrument       0.00      0.00      0.00       683\n",
      "               B-Location        nan      0.00      0.00      1157\n",
      "                B-Mission        nan      0.00      0.00       105\n",
      "                  B-Model       0.02      0.05      0.03      1412\n",
      "B-ObservationalTechniques        nan      0.00      0.00       102\n",
      "            B-Observatory        nan      0.00      0.00       735\n",
      "           B-Organization       0.02      0.04      0.02      6054\n",
      "                 B-Person       0.00      0.00      0.00      3267\n",
      "               B-Proposal        nan      0.00      0.00        76\n",
      "               B-Software       0.00      0.00      0.00       839\n",
      "                 B-Survey       0.00      0.01      0.01       620\n",
      "                    B-Tag       0.00      0.00      0.00        53\n",
      "              B-Telescope       0.00      0.00      0.00      1257\n",
      "            B-TextGarbage        nan      0.00      0.00        47\n",
      "                    B-URL       0.00      0.00      0.00       227\n",
      "             B-Wavelength       0.04      0.04      0.04      2869\n",
      "                I-Archive        nan      0.00      0.00       348\n",
      "        I-CelestialObject       0.00      0.00      0.00      1347\n",
      "  I-CelestialObjectRegion        nan      0.00      0.00       139\n",
      "        I-CelestialRegion        nan      0.00      0.00       275\n",
      "               I-Citation       0.30      0.57      0.39     14072\n",
      "          I-Collaboration       0.00      0.00      0.00       437\n",
      "      I-ComputingFacility        nan      0.00      0.00       690\n",
      "               I-Database        nan      0.00      0.00       225\n",
      "                I-Dataset        nan      0.00      0.00       232\n",
      " I-EntityOfFutureInterest        nan      0.00      0.00        13\n",
      "                  I-Event        nan      0.00      0.00       170\n",
      "             I-Fellowship        nan      0.00      0.00       839\n",
      "                I-Formula        nan      0.00      0.00      6482\n",
      "                  I-Grant        nan      0.00      0.00      3594\n",
      "             I-Identifier       0.00      0.00      0.00        26\n",
      "             I-Instrument        nan      0.00      0.00       176\n",
      "               I-Location        nan      0.00      0.00       397\n",
      "                I-Mission        nan      0.00      0.00        43\n",
      "                  I-Model        nan      0.00      0.00      1025\n",
      "I-ObservationalTechniques        nan      0.00      0.00        88\n",
      "            I-Observatory       0.92      0.01      0.02      1001\n",
      "           I-Organization       0.00      0.00      0.00     12021\n",
      "                 I-Person       0.00      0.03      0.00      1948\n",
      "               I-Proposal        nan      0.00      0.00        87\n",
      "               I-Software       0.00      0.01      0.00       269\n",
      "                 I-Survey        nan      0.00      0.00       380\n",
      "                    I-Tag        nan      0.00      0.00        51\n",
      "              I-Telescope       0.00      0.01      0.00       596\n",
      "            I-TextGarbage        nan      0.00      0.00        55\n",
      "                    I-URL        nan      0.00      0.00         1\n",
      "             I-Wavelength        nan      0.00      0.00      1895\n",
      "\n",
      "                micro avg       0.06      0.11      0.08     81838\n",
      "                macro avg       0.05      0.02      0.01     81838\n",
      "             weighted avg       0.09      0.11      0.08     81838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7616d0d9-129e-4fb9-abc7-72226a47a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a passive aggressive classifer\n",
    "pa = PassiveAggressiveClassifier()\n",
    "# fit and predict\n",
    "pa.partial_fit(X_train, y_train, labels)\n",
    "y_pred = pa.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2837c9fe-5ea3-460c-8e57-4cf96254af0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                B-Archive        nan      0.00      0.00       153\n",
      "        B-CelestialObject       0.00      0.00      0.00      2285\n",
      "  B-CelestialObjectRegion        nan      0.00      0.00       150\n",
      "        B-CelestialRegion       0.00      0.00      0.00       102\n",
      "               B-Citation       0.05      0.48      0.09      4820\n",
      "          B-Collaboration        nan      0.00      0.00       238\n",
      "      B-ComputingFacility       0.00      0.00      0.00       360\n",
      "               B-Database        nan      0.00      0.00       199\n",
      "                B-Dataset        nan      0.00      0.00       222\n",
      " B-EntityOfFutureInterest        nan      0.00      0.00        52\n",
      "                  B-Event        nan      0.00      0.00        37\n",
      "             B-Fellowship       0.00      0.00      0.00       326\n",
      "                B-Formula        nan      0.00      0.00      1541\n",
      "                  B-Grant        nan      0.00      0.00      2834\n",
      "             B-Identifier        nan      0.00      0.00        94\n",
      "             B-Instrument       0.00      0.00      0.00       683\n",
      "               B-Location       0.00      0.00      0.00      1157\n",
      "                B-Mission       0.00      0.00      0.00       105\n",
      "                  B-Model       0.00      0.00      0.00      1412\n",
      "B-ObservationalTechniques        nan      0.00      0.00       102\n",
      "            B-Observatory        nan      0.00      0.00       735\n",
      "           B-Organization       0.00      0.00      0.00      6054\n",
      "                 B-Person       0.01      0.13      0.02      3267\n",
      "               B-Proposal        nan      0.00      0.00        76\n",
      "               B-Software       0.02      0.11      0.04       839\n",
      "                 B-Survey       0.00      0.00      0.00       620\n",
      "                    B-Tag        nan      0.00      0.00        53\n",
      "              B-Telescope       0.00      0.00      0.00      1257\n",
      "            B-TextGarbage        nan      0.00      0.00        47\n",
      "                    B-URL        nan      0.00      0.00       227\n",
      "             B-Wavelength        nan      0.00      0.00      2869\n",
      "                I-Archive        nan      0.00      0.00       348\n",
      "        I-CelestialObject        nan      0.00      0.00      1347\n",
      "  I-CelestialObjectRegion       0.00      0.00      0.00       139\n",
      "        I-CelestialRegion        nan      0.00      0.00       275\n",
      "               I-Citation        nan      0.00      0.00     14072\n",
      "          I-Collaboration        nan      0.00      0.00       437\n",
      "      I-ComputingFacility        nan      0.00      0.00       690\n",
      "               I-Database       0.00      0.00      0.00       225\n",
      "                I-Dataset        nan      0.00      0.00       232\n",
      " I-EntityOfFutureInterest        nan      0.00      0.00        13\n",
      "                  I-Event        nan      0.00      0.00       170\n",
      "             I-Fellowship        nan      0.00      0.00       839\n",
      "                I-Formula        nan      0.00      0.00      6482\n",
      "                  I-Grant        nan      0.00      0.00      3594\n",
      "             I-Identifier        nan      0.00      0.00        26\n",
      "             I-Instrument        nan      0.00      0.00       176\n",
      "               I-Location        nan      0.00      0.00       397\n",
      "                I-Mission        nan      0.00      0.00        43\n",
      "                  I-Model        nan      0.00      0.00      1025\n",
      "I-ObservationalTechniques        nan      0.00      0.00        88\n",
      "            I-Observatory       0.00      0.00      0.00      1001\n",
      "           I-Organization        nan      0.00      0.00     12021\n",
      "                 I-Person        nan      0.00      0.00      1948\n",
      "               I-Proposal        nan      0.00      0.00        87\n",
      "               I-Software        nan      0.00      0.00       269\n",
      "                 I-Survey       0.00      0.00      0.00       380\n",
      "                    I-Tag       0.00      0.00      0.00        51\n",
      "              I-Telescope        nan      0.00      0.00       596\n",
      "            I-TextGarbage        nan      0.00      0.00        55\n",
      "                    I-URL        nan      0.00      0.00         1\n",
      "             I-Wavelength       0.00      0.00      0.00      1895\n",
      "\n",
      "                micro avg       0.02      0.03      0.03     81838\n",
      "                macro avg       0.00      0.01      0.00     81838\n",
      "             weighted avg       0.01      0.03      0.01     81838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate how the perceptron did\n",
    "report(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5cacf4a0-87e0-4151-8d67-73c1250479cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a naive bayes classifier for multinomial models\n",
    "# this requires no negative values in the input\n",
    "# so make it a pipeline fronted by a minmaxscaler that\n",
    "# will scale all the features to fit into (0, 10)\n",
    "# TODO: play around with the feature range, (0, 10) performs better than (0, 1). why? what are good values?\n",
    "nb = Pipeline([\n",
    "    ('scaling', MinMaxScaler(feature_range=(0, 10))),\n",
    "    ('multinominalNB', MultinomialNB(alpha=0.01)),\n",
    "])\n",
    "# and fit and train\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06a0de5b-68af-4469-a838-b2298392c005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                B-Archive        nan      0.00      0.00       153\n",
      "        B-CelestialObject        nan      0.00      0.00      2285\n",
      "  B-CelestialObjectRegion        nan      0.00      0.00       150\n",
      "        B-CelestialRegion        nan      0.00      0.00       102\n",
      "               B-Citation        nan      0.00      0.00      4820\n",
      "          B-Collaboration        nan      0.00      0.00       238\n",
      "      B-ComputingFacility        nan      0.00      0.00       360\n",
      "               B-Database        nan      0.00      0.00       199\n",
      "                B-Dataset        nan      0.00      0.00       222\n",
      " B-EntityOfFutureInterest        nan      0.00      0.00        52\n",
      "                  B-Event        nan      0.00      0.00        37\n",
      "             B-Fellowship        nan      0.00      0.00       326\n",
      "                B-Formula        nan      0.00      0.00      1541\n",
      "                  B-Grant        nan      0.00      0.00      2834\n",
      "             B-Identifier        nan      0.00      0.00        94\n",
      "             B-Instrument        nan      0.00      0.00       683\n",
      "               B-Location        nan      0.00      0.00      1157\n",
      "                B-Mission        nan      0.00      0.00       105\n",
      "                  B-Model        nan      0.00      0.00      1412\n",
      "B-ObservationalTechniques        nan      0.00      0.00       102\n",
      "            B-Observatory        nan      0.00      0.00       735\n",
      "           B-Organization        nan      0.00      0.00      6054\n",
      "                 B-Person       0.00      0.00      0.00      3267\n",
      "               B-Proposal        nan      0.00      0.00        76\n",
      "               B-Software        nan      0.00      0.00       839\n",
      "                 B-Survey        nan      0.00      0.00       620\n",
      "                    B-Tag        nan      0.00      0.00        53\n",
      "              B-Telescope        nan      0.00      0.00      1257\n",
      "            B-TextGarbage        nan      0.00      0.00        47\n",
      "                    B-URL        nan      0.00      0.00       227\n",
      "             B-Wavelength        nan      0.00      0.00      2869\n",
      "                I-Archive        nan      0.00      0.00       348\n",
      "        I-CelestialObject        nan      0.00      0.00      1347\n",
      "  I-CelestialObjectRegion        nan      0.00      0.00       139\n",
      "        I-CelestialRegion        nan      0.00      0.00       275\n",
      "               I-Citation        nan      0.00      0.00     14072\n",
      "          I-Collaboration        nan      0.00      0.00       437\n",
      "      I-ComputingFacility        nan      0.00      0.00       690\n",
      "               I-Database        nan      0.00      0.00       225\n",
      "                I-Dataset        nan      0.00      0.00       232\n",
      " I-EntityOfFutureInterest        nan      0.00      0.00        13\n",
      "                  I-Event        nan      0.00      0.00       170\n",
      "             I-Fellowship        nan      0.00      0.00       839\n",
      "                I-Formula        nan      0.00      0.00      6482\n",
      "                  I-Grant        nan      0.00      0.00      3594\n",
      "             I-Identifier        nan      0.00      0.00        26\n",
      "             I-Instrument        nan      0.00      0.00       176\n",
      "               I-Location        nan      0.00      0.00       397\n",
      "                I-Mission        nan      0.00      0.00        43\n",
      "                  I-Model        nan      0.00      0.00      1025\n",
      "I-ObservationalTechniques        nan      0.00      0.00        88\n",
      "            I-Observatory        nan      0.00      0.00      1001\n",
      "           I-Organization        nan      0.00      0.00     12021\n",
      "                 I-Person        nan      0.00      0.00      1948\n",
      "               I-Proposal        nan      0.00      0.00        87\n",
      "               I-Software        nan      0.00      0.00       269\n",
      "                 I-Survey        nan      0.00      0.00       380\n",
      "                    I-Tag        nan      0.00      0.00        51\n",
      "              I-Telescope        nan      0.00      0.00       596\n",
      "            I-TextGarbage        nan      0.00      0.00        55\n",
      "                    I-URL        nan      0.00      0.00         1\n",
      "             I-Wavelength        nan      0.00      0.00      1895\n",
      "\n",
      "                micro avg       0.00      0.00      0.00     81838\n",
      "                macro avg       0.00      0.00      0.00     81838\n",
      "             weighted avg       0.00      0.00      0.00     81838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81fdf84d-ad96-4c21-ab08-c6fad238ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try something different. for embeddings, let's use astroBERT directly\n",
    "# credit to https://huggingface.co/adsabs/astroBERT\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c25a1433-d79c-4a05-9781-db276cf5c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from huggingface\n",
    "remote_model_path = 'adsabs/astroBERT'\n",
    "# instantiate the tokenizer\n",
    "astroBERT_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=remote_model_path,\n",
    "                                                    auth_token=True,\n",
    "                                                    add_special_tokens=True,\n",
    "                                                    do_lower_case=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81a59fbc-e9b2-4e64-86a8-db2b321a00ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.embeddings.position_ids', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "astroBERT_automodel = TFAutoModel.from_pretrained(remote_model_path, \n",
    "                                                  token=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4b1942b-5363-4c8f-b048-03746068750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = list(chain(*df[\"tokens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfde7351-887e-4a8e-b00a-6c0dc6a337b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize our, errr, tokens\n",
    "tokens = astroBERT_tokenizer(all_tokens, padding=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99c3313b-0775-49b7-b2a0-4f7bc0ad5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(573132, 37), dtype=int32, numpy=\n",
       "array([[16338, 16133, 16341, ..., 16340, 16340, 16340],\n",
       "       [16338, 16348, 16341, ..., 16340, 16340, 16340],\n",
       "       [16338, 25274, 16341, ..., 16340, 16340, 16340],\n",
       "       ...,\n",
       "       [16338, 22117, 16341, ..., 16340, 16340, 16340],\n",
       "       [16338,  7483, 16341, ..., 16340, 16340, 16340],\n",
       "       [16338, 22406, 16341, ..., 16340, 16340, 16340]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(573132, 37), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(573132, 37), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154d1a4a-ed31-4369-bb8a-878918db9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dies miserably with a kernel crash. don't know why?\n",
    "# output = astroBERT_automodel(**tokens, output_hidden_states=False)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
